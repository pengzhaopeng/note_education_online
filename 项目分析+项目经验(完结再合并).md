# 集群安装过程中注意事项

- 尽量使用离线方式安装

- 一定要使用非 root 用户，配置免密码的sudo权限

- 确认HDFS 的存储目录，保证存储在空间最大硬盘上

  ![](images/Snipaste_2020-01-09_23-50-17.png)

- 元数据备份（重点，如数据损坏，可能整个集群无法运行，至少要保证每日零点之后备份到其他服务器两个副本）
- 基准测试
- 参数调优 参考文档



# 用户行为分析（离线）

## 需求一、数据采集

![](images/Snipaste_2020-01-09_23-53-31.png)

![](images/Snipaste_2020-01-09_23-55-22.png)



**检查点** 和 **备份检查点**都会打开，如果检查点挂了，恢复数据会比较慢

```xml
hdfs-sink三个参数 （有一个生效就会直接用）
参考：https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#hdfs-sink
```

| 参数              | 默认配置 | 一般配置           |
| ----------------- | -------- | ------------------ |
| hdfs.rollInterval | 30       | 600 （10分钟）     |
| hdfs.rollSize     | 1024     | 1024*128 （128mb） |
| hdfs.rollCount    | 10       | 0 (切记设置成0)    |

小文件对集群的影响：

- 影响 namenode 内存
- 影响磁盘寻址
- mr 一个小文件就是 一个任务 影响性能

![](images/Snipaste_2020-01-12_15-36-03.png)

==**Flume分层**==

- **面试题**：一般生产环境分为2层

  **1、**如果只有一层，日志采集服务器非常多，此时会有很多个 Flume agent, 同时香HDFS写数据会产生多个client, 对 HDFS 压力太大了

  **2、**只有一层时，部分业务配置只能在这层配置，如后续配置修改，则要修改的位置太多，不利于后期维护

- **采集层**

  1、使用 **supervior**方式实现挂掉后自动重启 （找运维装）

  2、JVM一般设置 **512M** 即可 

  ```shell
  #（flume-env.sh java堆大小）
  export JAVA_OPTS="-Xms100m -Xmx200m -Dcom.sun.management.jmxremote"
  ```

  3、与业务服务器部署在一起

- **汇聚层**

  1、使用 load_balance

  2、JVM 一般设置为 4G

  3、部署在单独的服务器 （最低：4核8线程16GB内存）

- **jvm调优**

  1、-Xmx 与 -Xms 设置一样，减少内存抖动带来的性能影响

- 基于上面的双层架构图分析 Flume 如何保证数据至少处理一次

  1、采集层 agent 挂掉

  2、采集层服务器挂掉

  3、汇总层 agent 部分挂掉

- 思考题

  1、什么情况下会出现数据重复？举一个场景即可

  答：往HDFS成功写数据，此时sink应该告诉 channle写成功了，但是因为网络抖动还是断开，channle发的信号超时了，无法返回写入成功的信号。此时会把数据弄到 channle再写一次（事务）

  2、现在汇聚层向 HDFS 写数据事， channel中积压了大量的数据，有哪些解决方案？

# 项目中碰到的问题

**1）CDH修改配置文件不生效**

**2）**公司机房，服务器没上**UPS**（给你个缓冲，保证断电后1-2小时服务器**正常运行**，如果还没有来电，能给你缓冲让你手动保证服务器进程**优雅的关闭**）, 突然有一天断电了，然后来电再重启，庆幸发现所有服务没有问题，但是在一个月后的一天，突然集群恢复到一个月之前

​	原因：元数据存在mysql,mysql配置了HA, 重启恢复连接的那台mysql 数据确实是一个月前的数据。就是因为那次断电，导致两个mysql没办法同步数据，一个主一个从，正好重启那次还是读的主，运行了两个多月，两台一直没有同步。然后再手动切到主mysql,发现启动不来了，就是这个过程发现了脏数据。然后没办法只能一条数据一条数据的去找，找了两天把问题解决了（主mysql倒退往前删一天,删前要保存，再测试启动，能启动，再去一条条比对这天的数据，否则继续删）。

所以后面改成了**冷备 （凌晨将mysq中的元数据dump到其他两个机器上）**，**这里热备指的是mysql 配置HA**, 后面上了 UPS 改成热备也没问题

**3） flume启动问题：启动不报错**，但是HDFS就是接受不到数据

​	查看 flume/conf/log4j.properti 里面设置的日志级别，然后动态调整为DEBUG 级别：

![](images/Snipaste_2020-01-09_23-34-40.png)

**举一反三** 查看hive, 同样找到og4j.properti 

![](/images/Snipaste_2020-01-09_23-36-46.png)



**4） 你们会用 Flume 做 ETL工作吗？**

​	拉钩就是这做的，会发现性能上不来，吞吐量根本上不来

​	1、flume本身就不适合做数据清洗，如果如按不同key发到不同地方还行，但如果要去改key的话就不适合

​	2、flume 过滤掉了后期怎么做 数据质量监控，后面拿到的数据全是正确的，过滤掉的数据不一定是有问题的数据，可能是因为前端程序员的bug导致。

